//
//  FaceTrackingView.swift
//  Test
//
//  Created by æ¸¸å“²ç¶­ on 2025/2/16.
//

import Foundation
import SwiftUI
import ARKit
import RealityKit
import AVFoundation   // ç‚ºäº†ä½¿ç”¨ AVAssetWriter, AVAssetWriterInput ç­‰

enum TurnDirection {
    case left
    case right
}

struct FaceTrackingView: UIViewControllerRepresentable {
    @Binding var isVerified: Bool  // âœ… ç”¨ä¾†é€šçŸ¥é©—è­‰æˆåŠŸ
    @Binding var message: String   // âœ… ç”¨ä¾†é¡¯ç¤ºæŒ‡ç¤ºï¼ˆå‘å·¦è½‰ã€å‘å³è½‰ï¼‰

    func makeUIViewController(context: Context) -> FaceTrackingViewController {
        return FaceTrackingViewController(isVerified: $isVerified, message: $message)
    }

    func updateUIViewController(_ uiViewController: FaceTrackingViewController, context: Context) {}
}

class FaceTrackingViewController: UIViewController, ARSessionDelegate, AVCaptureVideoDataOutputSampleBufferDelegate {
    var arView = ARView(frame: .zero)
    var captureSession: AVCaptureSession!
    var videoOutput: AVCaptureVideoDataOutput!
    
    @Binding var isVerified: Bool
    @Binding var message: String
    
    // ç”¨ä¾†è¨˜éŒ„ä¸‹ä¸€å€‹æŒ‡ä»¤è¦ç”¨æˆ¶è½‰å“ªé‚Š
    var nextDirection: TurnDirection = Bool.random() ? .left : .right
    
    // è½‰é ­æª¢æ¸¬æ§åˆ¶
    var count: Int = 0
    var canDetectRightTurn = true
    var canDetectLeftTurn = true
    
    // MARK: - Video Writing Properties
    var assetWriter: AVAssetWriter?
    var writerInput: AVAssetWriterInput?
    var adaptor: AVAssetWriterInputPixelBufferAdaptor?
    var isRecording = false
    var currentFrameCount: Int64 = 0  // ç”¨ä¾†è¨ˆç®—å½±ç‰‡æ™‚é–“

    init(isVerified: Binding<Bool>, message: Binding<String>) {
        self._isVerified = isVerified
        self._message = message
        super.init(nibName: nil, bundle: nil)
    }

    required init?(coder: NSCoder) { fatalError("init(coder:) has not been implemented") }

    override func viewDidLoad() {
        super.viewDidLoad()
        setupARSession()
        
        // å¦‚æœæƒ³ç«‹å³é–‹å§‹éŒ„è£½ï¼Œå°±åœ¨é€™è£¡è¨­å®š
        setupVideoWriter()
        startRecording()
    }

    /// è¨­å®š ARKit è‡‰éƒ¨è¿½è¹¤
    func setupARSession() {
        guard ARFaceTrackingConfiguration.isSupported else {
            message = "âš ï¸ æ­¤è¨­å‚™ä¸æ”¯æ´è‡‰éƒ¨è¿½è¹¤"
            return
        }

        let configuration = ARFaceTrackingConfiguration()
        arView.session.delegate = self
        arView.session.run(configuration, options: [.resetTracking, .removeExistingAnchors])
        arView.translatesAutoresizingMaskIntoConstraints = false
        view.addSubview(arView)
        NSLayoutConstraint.activate([
            arView.topAnchor.constraint(equalTo: view.topAnchor),
            arView.leadingAnchor.constraint(equalTo: view.leadingAnchor),
            arView.trailingAnchor.constraint(equalTo: view.trailingAnchor),
            arView.bottomAnchor.constraint(equalTo: view.bottomAnchor)
        ])
    }

    /// æ¯ç•¶ ARKit æ›´æ–° anchors æ™‚ï¼Œå°±æœƒå‘¼å«é€™è£¡ï¼Œå¯ç”¨ä¾†åˆ¤æ–·é ­éƒ¨æ—‹è½‰
    func session(_ session: ARSession, didUpdate anchors: [ARAnchor]) {
        guard let faceAnchor = anchors.first as? ARFaceAnchor else { return }

        let yaw = faceAnchor.transform.columns.2.x // é ­éƒ¨æ°´å¹³æ—‹è½‰è§’åº¦
        DispatchQueue.main.async {
            switch self.nextDirection {
            case .right:
                // æŒ‡ç¤ºç”¨æˆ¶å‘å³è½‰
                if yaw > 0.4 && self.canDetectRightTurn {
                    // å®Œæˆä¸€æ¬¡å³è½‰
                    self.canDetectRightTurn = false
                    
                    if self.count == 1 {
                        self.message = "âœ… å‘å³è½‰æˆåŠŸï¼é©—è­‰å®Œæˆ"
                        self.isVerified = true
                        self.stopRecordingIfNeeded()
                    } else {
                        // å°šæœªåˆ°é”æœ€å¾Œä¸€æ¬¡è½‰é ­
                        self.nextDirection = Bool.random() ? .left : .right
                        if self.nextDirection == .left {
                            self.message = "âœ… å‘å³è½‰æˆåŠŸï¼æ¥ä¸‹ä¾†è«‹å‘å·¦è½‰"
                            self.count += 1
                        } else {
                            self.message = "âœ… å‘å³è½‰æˆåŠŸï¼æ¥ä¸‹ä¾†è«‹å‘å³è½‰"
                            self.count += 1
                        }
                    }
                    // æ¥ä¸‹ä¾†è‹¥æƒ³è¦ç”¨æˆ¶è½‰å·¦ï¼Œå°±æŠŠ nextDirection æ”¹æˆ .left
                } else {
                    // åªæœ‰ç•¶ abs(yaw) < 0.1ï¼Œæ‰å…è¨±å†åµæ¸¬ä¸‹ä¸€æ¬¡å³è½‰
                    if abs(yaw) < 0.1 {
                        self.canDetectRightTurn = true
                    }
                    if self.count == 0 {
                        self.message = "è«‹å…ˆå‘å³è½‰"
                    }
                }
                
            case .left:
                // æŒ‡ç¤ºç”¨æˆ¶å‘å·¦è½‰
                
                if yaw < -0.4 && self.canDetectLeftTurn {
                    self.canDetectLeftTurn = false
                    
                    if self.count == 1 {
                        self.message = "âœ… å‘å·¦è½‰æˆåŠŸï¼é©—è­‰å®Œæˆ"
                        self.isVerified = true
                        self.stopRecordingIfNeeded()
                    } else {
                        // å°šæœªåˆ°é”æœ€å¾Œä¸€æ¬¡è½‰é ­
                        self.nextDirection = Bool.random() ? .left : .right
                        if self.nextDirection == .left {
                            self.message = "âœ… å‘å·¦è½‰æˆåŠŸï¼æ¥ä¸‹ä¾†è«‹å‘å·¦è½‰"
                            self.count += 1
                        } else {
                            self.message = "âœ… å‘å·¦è½‰æˆåŠŸï¼æ¥ä¸‹ä¾†è«‹å‘å³è½‰"
                            self.count += 1
                        }
                    }
                } else {
                    // åªæœ‰ç•¶ abs(yaw) > -0.1ï¼Œæ‰å…è¨±å†åµæ¸¬ä¸‹ä¸€æ¬¡å·¦è½‰
                    if abs(yaw) > -0.1 {
                        self.canDetectLeftTurn = true
                    }
                    if self.count == 0 {
                        self.message = "è«‹å…ˆå‘å·¦è½‰"
                    }
                }
            }
        }
    }
    
    /// **é—œéµï¼š** æ¯å¹€å½±åƒæ›´æ–°éƒ½æœƒé€²åˆ°é€™è£¡ï¼Œå¯ç”¨ä¾†ä¸Šå‚³åˆ°å¾Œç«¯
    func session(_ session: ARSession, didUpdate frame: ARFrame) {
        // é€™å°±æ˜¯ ARKit å¾å‰é¡é ­æŠ“åˆ°çš„ç•¶å‰å½±åƒ (CVPixelBuffer)
        let pixelBuffer = frame.capturedImage
        // 1. å¯«åˆ° mp4 (å¦‚æœæ­£åœ¨éŒ„å½±)
        appendPixelBufferToWriter(pixelBuffer, timestamp: frame.timestamp)
        // è½‰æˆ JPEG
//        if let imageData = convertPixelBufferToJPEG(pixelBuffer) {
//            // ä¸Šå‚³åˆ°å¾Œç«¯
//            sendImageToServer(imageData: imageData)
//        }
    }

    /// å°‡ ARKit çš„ CVPixelBuffer è½‰æˆ JPEG Data
    func convertPixelBufferToJPEG(_ pixelBuffer: CVPixelBuffer) -> Data? {
        let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
        let context = CIContext()
        guard let cgImage = context.createCGImage(ciImage, from: ciImage.extent) else { return nil }

        let uiImage = UIImage(cgImage: cgImage)
        return uiImage.jpegData(compressionQuality: 0.5)
    }

    /// å°‡ JPEG Data ä¸Šå‚³è‡³å¾Œç«¯
    func sendImageToServer(imageData: Data) {
        // é€™è£¡åªæ˜¯ç¤ºç¯„ç”¨
        let url = URL(string: "https://your-api.com/upload-face")!
        var request = URLRequest(url: url)
        request.httpMethod = "POST"

        let boundary = UUID().uuidString
        request.setValue("multipart/form-data; boundary=\(boundary)", forHTTPHeaderField: "Content-Type")

        var body = Data()
        body.append("--\(boundary)\r\n".data(using: .utf8)!)
        body.append("Content-Disposition: form-data; name=\"file\"; filename=\"face.jpg\"\r\n".data(using: .utf8)!)
        body.append("Content-Type: image/jpeg\r\n\r\n".data(using: .utf8)!)
        body.append(imageData)
        body.append("\r\n--\(boundary)--\r\n".data(using: .utf8)!)

        request.httpBody = body

        URLSession.shared.dataTask(with: request) { data, response, error in
            if let error = error {
//                print("âŒ å½±åƒå‚³è¼¸å¤±æ•—: \(error.localizedDescription)")
            } else {
//                print("âœ… å½±åƒæˆåŠŸå‚³è¼¸åˆ°å¾Œç«¯ï¼")
            }
        }.resume()
    }
}

// MARK: - MP4 éŒ„å½±ç›¸é—œé‚è¼¯ (AVAssetWriter)
extension FaceTrackingViewController {

    /// è¨­å®š AVAssetWriterã€AVAssetWriterInputã€PixelBufferAdaptor
    func setupVideoWriter() {
        // 1. è¨­å®šè¼¸å‡ºæª”æ¡ˆè·¯å¾‘ï¼ˆé€™è£¡æ”¾æš«å­˜ç›®éŒ„ï¼‰
        let outputURL = FileManager.default.temporaryDirectory.appendingPathComponent("faceVideo.mp4")
        // è‹¥å·²å­˜åœ¨åŒåæª”æ¡ˆï¼Œå…ˆåˆªæ‰
        try? FileManager.default.removeItem(at: outputURL)

        do {
            assetWriter = try AVAssetWriter(outputURL: outputURL, fileType: .mp4)
        } catch {
            print("âŒ ç„¡æ³•å»ºç«‹ AVAssetWriter: \(error)")
            return
        }

        // 2. è¨­å®šå½±åƒè¼¸å‡ºåƒæ•¸ (H.264, 640x480 åªæ˜¯ä¸€å€‹ç¤ºä¾‹)
        let videoSettings: [String: Any] = [
            AVVideoCodecKey: AVVideoCodecType.h264,
            AVVideoWidthKey: 640,
            AVVideoHeightKey: 480
        ]
        writerInput = AVAssetWriterInput(mediaType: .video, outputSettings: videoSettings)
        writerInput?.expectsMediaDataInRealTime = true

        // 3. å»ºç«‹ PixelBuffer Adaptor (å‡è¨­ 32BGRA)
        adaptor = AVAssetWriterInputPixelBufferAdaptor(
            assetWriterInput: writerInput!,
            sourcePixelBufferAttributes: [
                kCVPixelBufferPixelFormatTypeKey as String: kCVPixelFormatType_32BGRA
            ]
        )

        // 4. åŠ å…¥åˆ° writer
        if let writer = assetWriter, let input = writerInput, writer.canAdd(input) {
            writer.add(input)
        }
    }

    /// é–‹å§‹éŒ„è£½
    func startRecording() {
        guard let writer = assetWriter else { return }
        // é–‹å§‹å¯«
        writer.startWriting()
        writer.startSession(atSourceTime: .zero)
        currentFrameCount = 0
        isRecording = true
        print("ğŸ¬ é–‹å§‹éŒ„å½±: \(writer.outputURL)")
    }

    /// åœæ­¢éŒ„è£½
    func stopRecordingIfNeeded() {
        guard isVerified, isRecording else { return } // è‹¥å·²é©—è­‰æˆ–æ­£åœ¨éŒ„å½±æ‰åœæ­¢
        stopRecording()
    }

    func stopRecording() {
        guard isRecording else { return }
        isRecording = false

        writerInput?.markAsFinished()
        assetWriter?.finishWriting { [weak self] in
            if let writer = self?.assetWriter {
                print("âœ… éŒ„å½±å®Œæˆï¼Œæª”æ¡ˆä½ç½®: \(writer.outputURL)")
            }
        }
    }

    /// å°‡ ARKit æ¯å¹€çš„ pixelBuffer å¯«å…¥ .mp4
    func appendPixelBufferToWriter(_ pixelBuffer: CVPixelBuffer, timestamp: TimeInterval) {
        guard isRecording,
              let writer = assetWriter,
              let input = writerInput,
              let adaptor = adaptor else { return }

        // æª¢æŸ¥æ˜¯å¦å¯ä»¥å¯«
        if input.isReadyForMoreMediaData {
            // è½‰æˆ .bgra
            var tempBuffer: CVPixelBuffer? = nil
            let status = CVPixelBufferCreate(nil,
                                             CVPixelBufferGetWidth(pixelBuffer),
                                             CVPixelBufferGetHeight(pixelBuffer),
                                             kCVPixelFormatType_32BGRA,
                                             nil,
                                             &tempBuffer)
            if status == kCVReturnSuccess, let dstBuffer = tempBuffer {
                // å°‡ pixelBuffer (å¯èƒ½æ˜¯ IR æ ¼å¼) è½‰æˆ BGRA
                // é€™è£¡ç”¨ä¸€å€‹ç°¡å–® CIContext è½‰æ›
                let ciImage = CIImage(cvPixelBuffer: pixelBuffer)
                let context = CIContext()
                context.render(ciImage, to: dstBuffer)

                // è¨ˆç®—ç•¶å‰å¹€çš„ presentationTime
                // ç”¨ timestamp ç•¶ç§’æ•¸, timescale=600 åªæ˜¯ç¯„ä¾‹
                let frameTime = CMTimeMakeWithSeconds(timestamp, preferredTimescale: 600)

                // append
                adaptor.append(dstBuffer, withPresentationTime: frameTime)
                currentFrameCount += 1
            }
        }
    }
}
